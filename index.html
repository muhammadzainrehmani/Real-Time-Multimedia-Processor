<!DOCTYPE html>
<html>

<head>
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css">
  <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>

  <style>
    .header {
      background-color: #8a3dff;
    }

    .footer {
      background-color: #8a3dff;
    }

    #videoElement {
      width: 420px;
      height: 340px;
      border-radius: 20px;
    }

    #canvasElement {
      display: none;
    }

    .demo-content {
      padding: 20px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    .button-group {
      margin-bottom: 25px;
    }

    /* Radio button styling */
    .radio-buttons {
      display: flex;
      align-items: center;
      /* gap: 20px; */
      margin: 10px 0;
    }

    .radio-buttons input[type="radio"] {
      accent-color: #8a3dff;
      width: 16px;
      height: 16px;
      margin-right: 5px;
    }

    .radio-buttons label {
      font-family: Arial, sans-serif;
      font-size: 14px;
      color: #333;
      cursor: pointer;
      padding: 5px;
      transition: background-color 0.3s ease;
      display: flex;
      align-items: center;
      gap: 5px;
    }

    .radio-buttons label:hover {
      background-color: #8b3dff76;
      border-radius: 4px;
    }

    .radio-buttons .material-icons {
      font-size: 18px;
    }

    /* Textarea Input field */
    #systemInstruction:focus {
      border: 2px solid #8a3dff;
      outline: none;
    }
  </style>
</head>

<body>
  <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
    <header class="mdl-layout__header header">
      <div class="mdl-layout__header-row">
        <!-- Title -->
        <span class="mdl-layout-title">Real-Time Multimedia Processor</span>
      </div>
    </header>
    <main class="mdl-layout__content">
      <div class="page-content">
        <div class="demo-content">
          <!-- Voice Control Buttons -->
          <div class="button-group">
            <button id="startButton"
              class="mdl-button mdl-js-button mdl-button--fab mdl-button--mini-fab mdl-button--colored">
              <i class="material-icons">mic</i>
            </button>
            <button id="stopButton" class="mdl-button mdl-js-button mdl-button--fab mdl-button--mini-fab">
              <i class="material-icons">mic_off</i>
            </button>
          </div>

          <!-- Radio Buttons -->
          <!-- <div>Model responce type</div>
                    <div class="radio-buttons">
                      <input type="radio" id="responseText" name="response_modality" value="TEXT">
                      <label for="responseText">
                        <i class="material-icons">text_fields</i>
                        Text
                      </label>
                      <input type="radio" id="responseVoice" name="response_modality" value="AUDIO">
                      <label for="responseVoice">
                        <i class="material-icons">volume_up</i>
                        Audio
                      </label>
                    </div> -->

          <!-- Video Element -->
          <video id="videoElement" autoplay></video>

          <!-- Hidden Canvas -->
          <canvas id="canvasElement"></canvas>
          <!-- Text Output -->
          <div id="chatLog"></div>
        </div>
      </div>
    </main>
    <footer class="footer">
      <div class="mdl-layout__header footer">
        <div class="mdl-layout__header-row" style="display: flex; justify-content: space-between; ">
          <span class="mdl-layout-title">Roll No: 21cs13</span>
          <span class="mdl-layout-title">Subject: Digital Image Processing</span>
          <span class="mdl-layout-title">Teacher: Prof. Dr. Fareed Ahmed Jokhio</span>
        </div>
      </div>
    </footer>
  </div>

  <script defer>
    const URL = "ws://localhost:9080";
    const video = document.getElementById("videoElement");
    const canvas = document.getElementById("canvasElement");
    const context = canvas.getContext("2d");
    const startButton = document.getElementById('startButton');
    const stopButton = document.getElementById('stopButton');
    let stream = null;
    let currentFrameB64;
    let webSocket = null;
    let audioContext = null;
    let mediaRecorder = null;
    let processor = null;
    let pcmData = [];
    let interval = null;
    let initialized = false;
    let audioInputContext;
    let workletNode;

    // Function to start the webcam
    async function startWebcam() {
      try {
        const constraints = {
          video: {
            width: {
              max: 640
            },
            height: {
              max: 480
            },
          },
        };

        stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
      } catch (err) {
        console.error("Error accessing the webcam: ", err);
      }
    }

    // Function to capture an image and convert it to base64
    function captureImage() {
      if (stream) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        const imageData = canvas.toDataURL("image/jpeg").split(",")[1].trim();
        currentFrameB64 = imageData;
      }
    }

    window.addEventListener("load", async () => {
      await startWebcam();
      setInterval(captureImage, 1000);
      connect();

    });

    function connect() {
      console.log("connecting: ", URL);

      webSocket = new WebSocket(URL);

      webSocket.onclose = (event) => {
        console.log("websocket closed: ", event);
        alert("Connection closed");
      };

      webSocket.onerror = (event) => {
        console.log("websocket error: ", event);
      };

      webSocket.onopen = (event) => {
        console.log("websocket open: ", event);
        sendInitialSetupMessage();
      };

      webSocket.onmessage = receiveMessage;
    }
    function sendInitialSetupMessage() {

      console.log("sending setup message");

      // Get the selected modality from the radio buttons
      // const modality = document.querySelector('input[name="response_modality"]:checked').value;

      setup_client_message = {
        setup: {
          generation_config: {
            response_modalities: ["AUDIO"]
          },
        },
      };

      webSocket.send(JSON.stringify(setup_client_message));
    }


    function sendVoiceMessage(b64PCM) {
      if (webSocket == null) {
        console.log("websocket not initialized");
        return;
      }

      payload = {
        realtime_input: {
          media_chunks: [{
            mime_type: "audio/pcm",
            data: b64PCM,
          },
          {
            mime_type: "image/jpeg",
            data: currentFrameB64,
          },
          ],
        },
      };

      webSocket.send(JSON.stringify(payload));
      console.log("sent: ", payload);
    }

    function receiveMessage(event) {
      const messageData = JSON.parse(event.data);
      const response = new Response(messageData);

      if (response.text) {
        displayMessage("GEMINI: " + response.text);
      }
      if (response.audioData) {
        injestAudioChuckToPlay(response.audioData);
      }
    }


    async function initializeAudioContext() {
      if (initialized) return;

      audioInputContext = new (window.AudioContext ||
        window.webkitAudioContext)({ sampleRate: 24000 });
      await audioInputContext.audioWorklet.addModule("pcm-processor.js");
      workletNode = new AudioWorkletNode(audioInputContext, "pcm-processor");
      workletNode.connect(audioInputContext.destination);
      initialized = true;
    }


    function base64ToArrayBuffer(base64) {
      const binaryString = window.atob(base64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      return bytes.buffer;
    }

    function convertPCM16LEToFloat32(pcmData) {
      const inputArray = new Int16Array(pcmData);
      const float32Array = new Float32Array(inputArray.length);

      for (let i = 0; i < inputArray.length; i++) {
        float32Array[i] = inputArray[i] / 32768;
      }

      return float32Array;
    }


    async function injestAudioChuckToPlay(base64AudioChunk) {
      try {
        if (!initialized) {
          await initializeAudioContext();
        }

        if (audioInputContext.state === "suspended") {
          await audioInputContext.resume();
        }
        const arrayBuffer = base64ToArrayBuffer(base64AudioChunk);
        const float32Data = convertPCM16LEToFloat32(arrayBuffer);

        workletNode.port.postMessage(float32Data);
      } catch (error) {
        console.error("Error processing audio chunk:", error);
      }
    }


    function recordChunk() {
      const buffer = new ArrayBuffer(pcmData.length * 2);
      const view = new DataView(buffer);
      pcmData.forEach((value, index) => {
        view.setInt16(index * 2, value, true);
      });

      const base64 = btoa(
        String.fromCharCode.apply(null, new Uint8Array(buffer))
      );

      sendVoiceMessage(base64);
      pcmData = [];
    }

    async function startAudioInput() {
      audioContext = new AudioContext({
        sampleRate: 16000,
      });

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 16000,
        },
      });

      const source = audioContext.createMediaStreamSource(stream);
      processor = audioContext.createScriptProcessor(4096, 1, 1);

      processor.onaudioprocess = (e) => {
        const inputData = e.inputBuffer.getChannelData(0);
        const pcm16 = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          pcm16[i] = inputData[i] * 0x7fff;
        }
        pcmData.push(...pcm16);
      };

      source.connect(processor);
      processor.connect(audioContext.destination);

      interval = setInterval(recordChunk, 3000);
    }

    function stopAudioInput() {
      if (processor) {
        processor.disconnect();
      }
      if (audioContext) {
        audioContext.close();
      }

      clearInterval(interval);
    }

    function displayMessage(message) {
      console.log(message);
      addParagraphToDiv("chatLog", message);
    }


    function addParagraphToDiv(divId, text) {
      const newParagraph = document.createElement("p");
      newParagraph.textContent = text;
      const div = document.getElementById(divId);
      div.appendChild(newParagraph);
    }

    startButton.addEventListener('click', startAudioInput);
    stopButton.addEventListener('click', stopAudioInput);


    class Response {
      constructor(data) {
        this.text = null;
        this.audioData = null;
        this.endOfTurn = null;

        if (data.text) {
          this.text = data.text
        }

        if (data.audio) {
          this.audioData = data.audio;
        }
      }
    }
  </script>
</body>

</html>